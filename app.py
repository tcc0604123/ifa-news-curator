import streamlit as st
import google.generativeai as genai
import feedparser
import requests
import json
import time
import ssl

# ==========================================
# 1. åŸºç¤è¨­å®šèˆ‡ SSL ä¿®å¾© (å¿…å‚™)
# ==========================================
st.set_page_config(page_title="IFA æ™ºèƒ½æ–°èç­–å±•", layout="wide")

# å¼·åˆ¶å¿½ç•¥ SSL æ†‘è­‰æª¢æŸ¥ (è§£æ±º RSS æŠ“å–å¤±æ•—å•é¡Œ)
try:
    _create_unverified_https_context = ssl._create_unverified_context
except AttributeError:
    pass
else:
    ssl._create_default_https_context = _create_unverified_https_context

# ==========================================
# 2. æ ¸å¿ƒåŠŸèƒ½å‡½æ•¸
# ==========================================

def get_active_model_name():
    """
    è‡ªå‹•åµæ¸¬å¯ç”¨æ¨¡å‹ï¼Œå„ªå…ˆé †åºï¼š
    1. gemini-1.5-flash (æœ€å¿«ã€é…é¡æœ€é«˜)
    2. gemini-1.5-pro 
    3. åˆ—è¡¨ä¸­çš„ç¬¬ä¸€å€‹å¯ç”¨æ¨¡å‹
    4. æœ€çµ‚å‚™æ¡ˆ: gemini-1.5-flash
    """
    try:
        # åˆ—å‡ºæ‰€æœ‰æ”¯æ´ç”Ÿæˆå…§å®¹çš„æ¨¡å‹
        models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        
        # 1. å„ªå…ˆæ‰¾ gemini-1.5-flash
        for m in models:
            if "gemini-1.5-flash" in m: 
                return m
                
        # 2. å…¶æ¬¡æ‰¾ gemini-1.5-pro
        for m in models:
            if "gemini-1.5-pro" in m: 
                return m
        
        # 3. å¦‚æœéƒ½æ²’æ‰¾åˆ°æŒ‡å®šåç¨±ï¼Œä½†åˆ—è¡¨ä¸ç‚ºç©ºï¼Œå›å‚³ç¬¬ä¸€å€‹
        if models:
            return models[0]
            
    except Exception as e:
        print(f"Model discovery error: {e}")
        pass

    # 4. æœ€çµ‚å‚™æ¡ˆ
    return "gemini-1.5-flash"

def get_generative_model(api_key):
    """
    å·¥å» å‡½æ•¸ï¼šå»ºç«‹æ¨¡å‹å¯¦ä¾‹
    """
    genai.configure(api_key=api_key)
    model_name = get_active_model_name()
    return genai.GenerativeModel(model_name), model_name

def fetch_news():
    """æŠ“å– Google News RSS æ–°è"""
    news_items = []
    
    # é‡å°å°ç£ç†è²¡é¡§å• (IFA) çš„ 5 å¤§æ ¸å¿ƒç¶­åº¦
    urls = [
        # 1. ç¸½ç¶“èˆ‡åœ‹éš›ï¼šé—œæ³¨è¯æº–æœƒã€ç¾è‚¡èˆ‡åŒ¯ç‡ï¼Œå½±éŸ¿è³‡ç”¢é…ç½®
        ("å…¨çƒç¸½ç¶“", "https://news.google.com/rss/search?q=è¯æº–æœƒ+OR+ç¾è‚¡+OR+ç¾å…ƒåŒ¯ç‡+OR+å¤®è¡Œå‡æ¯+when:1d&hl=zh-TW&gl=TW&ceid=TW:zh-TW"),
        
        # 2. æŠ•è³‡èˆ‡å¸‚å ´ï¼šå°è‚¡ã€ETF èˆ‡å‚µåˆ¸å¸‚å ´å‹•æ…‹
        ("æŠ•è³‡å¸‚å ´", "https://news.google.com/rss/search?q=å°ç£+è‚¡å¸‚+OR+ETF+é…æ¯+OR+å‚µåˆ¸æ®–åˆ©ç‡+when:1d&hl=zh-TW&gl=TW&ceid=TW:zh-TW"),
        
        # 3. ç¨…å‹™èˆ‡å‚³æ‰¿ï¼šé«˜è³‡ç”¢å®¢æˆ¶æœ€é—œæ³¨çš„éºç”¢ã€è´ˆèˆ‡èˆ‡ä¿¡è¨—
        ("ç¨…å‹™å‚³æ‰¿", "https://news.google.com/rss/search?q=å°ç£+éºç”¢ç¨…+OR+è´ˆèˆ‡ç¨…+OR+æˆ¿åœ°åˆä¸€+OR+å®¶æ—ä¿¡è¨—+when:1d&hl=zh-TW&gl=TW&ceid=TW:zh-TW"),
        
        # 4. ä¿éšªèˆ‡é¢¨éšªï¼šå°ˆæ³¨æ–¼ä¿éšœã€ç†è³ èˆ‡é•·ç…§é†«ç™‚
        ("ä¿éšªè¦åŠƒ", "https://news.google.com/rss/search?q=å°ç£+ä¿éšª+ç†è³ +OR+å¯¦æ”¯å¯¦ä»˜+OR+é•·ç…§éšª+OR+å¤±èƒ½éšª+when:1d&hl=zh-TW&gl=TW&ceid=TW:zh-TW"),
        
        # 5. é€€ä¼‘èˆ‡æˆ¿ç”¢ï¼šæˆ¿å¸‚å‹•æ…‹èˆ‡é€€ä¼‘é‡‘åˆ¶åº¦
        ("é€€ä¼‘æˆ¿ç”¢", "https://news.google.com/rss/search?q=å°ç£+é€€ä¼‘é‡‘+OR+å‹é€€+OR+æˆ¿å¸‚+OR+æˆ¿è²¸+OR+ä»¥æˆ¿é¤Šè€+when:1d&hl=zh-TW&gl=TW&ceid=TW:zh-TW")
    ]

    for category, url in urls:
        try:
            feed = feedparser.parse(url)
            # æ¯ä¸€é¡æŠ“å‰ 15 ç¯‡ï¼Œç¢ºä¿åŸæ–™å……è¶³
            for entry in feed.entries[:15]:
                news_items.append({
                    "category": category,
                    "title": entry.title,
                    "link": entry.link,
                    "source": entry.source.title if hasattr(entry, 'source') else "Google News",
                    "summary": entry.summary[:200] if hasattr(entry, 'summary') else ""
                })
        except Exception as e:
            print(f"Error fetching {category}: {e}")
            
    return news_items

def analyze_and_curate_news(all_raw_news, api_key):
    """
    AI ç¸½ç·¨æ¨¡å¼ï¼šæ¥æ”¶æ‰€æœ‰åŸå§‹æ–°èï¼Œç”± AI æŒ‘é¸æœ€é‡è¦ 6 å‰‡ä¸¦æ’°å¯«è©•è«–ã€‚
    """
    model, used_name = get_generative_model(api_key)
    
    # 1. æ•´ç†æ‰€æœ‰æ–°èç‚ºç²¾ç°¡æ¸…å–®ä¾› AI é–±è®€
    news_candidates = []
    for i, n in enumerate(all_raw_news):
        news_candidates.append({
            "id": i,
            "category": n['category'],
            "title": n['title'],
            "source": n['source']
        })
    
    news_json_block = json.dumps(news_candidates, ensure_ascii=False)

    # 2. å»ºæ§‹ç¸½ç·¨ç´š Prompt
    prompt = f"""
    ä½ æ˜¯å°ç£è³‡æ·±è²¡å‹™é¡§å•(IFA)çš„ã€Œæ–°èç¸½ç·¨è¼¯ã€ã€‚
    ä»¥ä¸‹æ˜¯ä»Šæ—¥æŠ“å–çš„ {len(all_raw_news)} å‰‡è²¡ç¶“æ–°èå€™é¸æ¸…å–®ï¼š
    {news_json_block}

    ã€ä»»å‹™ç›®æ¨™ã€‘ï¼š
    è«‹å¾ä¸­åš´é¸å‡º **æœ€é—œéµçš„ 6 å‰‡** æ–°èï¼Œè£½ä½œæˆçµ¦é«˜è³‡ç”¢å®¢æˆ¶çš„æ—¥å ±ã€‚

    ã€ç¯©é¸æ¨™æº– (ç”±é«˜è‡³ä½å„ªå…ˆ)ã€‘ï¼š
    1. **å¯¦è³ªå½±éŸ¿**ï¼šå„ªå…ˆé¸æ“‡ã€Œä¸‰è®€é€šéçš„æ³•è¦ã€ã€ã€Œç¢ºå®šçš„ç¨…å‹™æ”¹é©ã€ã€ã€Œè¯æº–æœƒ/å¤®è¡Œæ­£å¼æ±ºè­°ã€ã€ã€Œç¢ºå®šçš„é…æ¯/è²¡å ±æ•¸æ“šã€ã€‚
    2. **å®¢æˆ¶æ”¸é—œ**ï¼šèˆ‡ã€Œé€€ä¼‘è¦åŠƒã€ã€ã€Œè³‡ç”¢å‚³æ‰¿ã€ã€ã€Œæˆ¿åœ°ç”¢ç¨…å‹™ã€ç›´æ¥ç›¸é—œè€…å„ªå…ˆã€‚
    3. **é¡åˆ¥å¹³è¡¡**ï¼šè«‹ç›¡é‡ç¢ºä¿ã€Œå…¨çƒç¸½ç¶“ã€ã€ã€ŒæŠ•è³‡ã€ã€ã€Œç¨…å‹™å‚³æ‰¿ã€ã€ã€Œä¿éšªã€èˆ‡ã€Œé€€ä¼‘æˆ¿ç”¢ã€ç­‰é ˜åŸŸçš†æœ‰å…¥é¸ (é™¤éç•¶å¤©æŸé ˜åŸŸç„¡é‡è¦æ–°è)ã€‚
    4. **æ’é™¤åå–®**ï¼šåš´æ ¼æ’é™¤ã€Œç´”é æ¸¬/çŒœæ¸¬ã€ã€ã€Œåˆ¸å•†è¡ŒéŠ·å»£å‘Šã€ã€ã€Œèˆ‡å€‹äººç†è²¡ç„¡é—œçš„æ”¿æ²»å£æ°´ã€ã€‚

    ã€å›å‚³æ ¼å¼ã€‘ï¼š
    è«‹å›å‚³ä¸€å€‹ç´” JSON List (Array)ï¼ŒåŒ…å«æŒ‘é¸å‡ºçš„ 6 å€‹ç‰©ä»¶ã€‚æ¯å€‹ç‰©ä»¶æ¬„ä½å¦‚ä¸‹ï¼š
    {{
        "original_id": (å°æ‡‰ä¸Šæ–¹è¼¸å…¥æ¸…å–®çš„ id, int),
        "news_summary": "æ–°èæ‘˜è¦ (ä¸€å…©å¥è©±ï¼Œç¹é«”ä¸­æ–‡)",
        "advisor_view": ["è§€é»1 (è«‹é‡å°è³‡ç”¢é…ç½®æˆ–ç¨…å‹™å½±éŸ¿)", "è§€é»2"],
        "action": "è¡Œå‹•å»ºè­° (å…·é«”ã€å¯åŸ·è¡Œçš„å»ºè­°ï¼Œä¸€å…©å¥è©±)"
    }}
    
    è«‹ç›´æ¥å›å‚³ JSONï¼Œä¸è¦æœ‰ä»»ä½• markdown æ¨™è¨˜ã€‚
    """
    
    try:
        response = model.generate_content(prompt)
        cleaned_text = response.text.replace("```json", "").replace("```", "").strip()
        curated_data = json.loads(cleaned_text)
        return curated_data, used_name
    except Exception as e:
        st.error(f"AI ç¸½ç·¨ç¯©é¸å¤±æ•—: {e}")
        return [], used_name

# ==========================================
# 3. æ•´åˆæµç¨‹ (åŠ ä¸Šå¿«å–æ©Ÿåˆ¶)
# ==========================================

@st.cache_data(ttl=3600, show_spinner=False)
def run_curation_pipeline(api_key):
    """
    AI ç¸½ç·¨è‡ªå‹•ç­–å±•æµç¨‹ (Cached 1hr)
    æµç¨‹ï¼šFetch All -> AI Select Top 6 & Comment -> Merge -> Return
    """
    # 1. æŠ“å–æ‰€æœ‰æ–°è (åŸæ–™)
    raw_news = fetch_news()
    if not raw_news:
        return None, "ç„¡æ³•æŠ“å–æ–°èï¼Œè«‹æª¢æŸ¥ç¶²è·¯é€£æ¥ã€‚", "None"

    # 2. å‘¼å« AI ç¸½ç·¨é€²è¡Œç¯©é¸èˆ‡é»è©•
    curated_data, model_used = analyze_and_curate_news(raw_news, api_key)
    
    if not curated_data:
        return None, "AI ç¯©é¸å›æ‡‰ç‚ºç©ºï¼Œè«‹ç¨å¾Œå†è©¦ã€‚", model_used

    # 3. çµ„åˆçµæœ
    final_results = []
    
    # å»ºç«‹ id å°ç…§è¡¨ä»¥åŠ é€ŸæŸ¥è©¢
    raw_map = {i: n for i, n in enumerate(raw_news)}
    
    for item in curated_data:
        oid = item.get('original_id')
        if oid is not None and oid in raw_map:
            original_news = raw_map[oid]
            
            final_results.append({
                "news": original_news,
                "comment": {
                    "news_summary": item.get('news_summary', 'æ‘˜è¦ç”Ÿæˆä¸­...'),
                    "advisor_view": item.get('advisor_view', []),
                    "action": item.get('action', 'è©³é–±å…§æ–‡')
                }
            })
            
    return final_results, None, model_used

# ==========================================
# 4. ä¸»ç¨‹å¼ä»‹é¢ (UI)
# ==========================================

def main():
    st.title("ğŸ¤– IFA æ™ºèƒ½æ–°èç­–å±•ç³»çµ±")
    st.caption("è‡ªå‹•å½™æ•´ç¨…å‹™ã€é€€ä¼‘ã€æŠ•è³‡èˆ‡æˆ¿ç”¢è³‡è¨Šï¼Œç”Ÿæˆé¡§å•è§€é»ã€‚")

    # è™•ç† API Key (å„ªå…ˆè®€å– secretsï¼Œæ²’æœ‰å‰‡é¡¯ç¤ºè¼¸å…¥æ¡†)
    api_key = None
    if "GOOGLE_API_KEY" in st.secrets:
        api_key = st.secrets["GOOGLE_API_KEY"]
    else:
        api_key = st.sidebar.text_input("è«‹è¼¸å…¥ Google API Key", type="password")

    if not api_key:
        st.warning("è«‹å…ˆè¨­å®š API Key æ‰èƒ½é–‹å§‹é‹ä½œã€‚")
        return

    # æŒ‰éˆ•è§¸ç™¼
    if st.button("é–‹å§‹ç­–å±• (æ›´æ–°æ—¥å ±)"):
        with st.spinner("AI æ­£åœ¨é–±è®€ä¸¦æ•´ç†å…¨å°è²¡ç¶“æ–°è... (ç´„éœ€ 10-20 ç§’)"):
            results, error, model_used = run_curation_pipeline(api_key)
            
            if error:
                st.error(error)
            else:
                st.toast(f"ä½¿ç”¨æ¨¡å‹: {model_used} | è³‡æ–™å·²å¿«å–")
                
                # é¡¯ç¤ºçµæœ (é›™æ¬„æ’ç‰ˆ)
                st.divider()
                cols = st.columns(2)
                
                for idx, item in enumerate(results):
                    news = item['news']
                    comment = item['comment']
                    
                    with cols[idx % 2]:
                        with st.container(border=True):
                            st.subheader(news['title'])
                            st.caption(f"ç”± {news['source']} ç™¼å¸ƒæ–¼ {news['category']}")
                            
                            news_summary = comment.get('news_summary', 'æ‘˜è¦ç”Ÿæˆä¸­...')
                            advisor_view = "\n".join([f"- {p}" for p in comment.get('advisor_view', [])]) if comment else "AI ç”Ÿæˆä¸­æ–·"
                            action = comment.get('action', 'å»ºè­°è©³é–±åŸæ–‡') if comment else ""
                            
                            content = f"""
### ğŸ“° æ–°èæ‘˜è¦
{news_summary}

### ğŸ’¼ é¡§å•è§€é»
{advisor_view}

### ğŸš€ å»ºè­°è¡Œå‹•
{action}

[é–±è®€åŸæ–‡]({news['link']})
"""
                            st.markdown(content)
                            with st.expander("è¤‡è£½æ–‡æ¡ˆ"):
                                st.code(f"{news['title']}\n\n{content}", language="markdown")

if __name__ == "__main__":
    main()
