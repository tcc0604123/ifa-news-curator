import streamlit as st
import google.generativeai as genai
import feedparser
import requests
import json
import time
import ssl

# ==========================================
# 1. åŸºç¤è¨­å®šèˆ‡ SSL ä¿®å¾©
# ==========================================
st.set_page_config(page_title="IFA æ™ºèƒ½æ–°èç­–å±•", layout="wide")

# å¼·åˆ¶å¿½ç•¥ SSL æ†‘è­‰æª¢æŸ¥ (è§£æ±º RSS æŠ“å–å¤±æ•—å•é¡Œ)
try:
    _create_unverified_https_context = ssl._create_unverified_context
except AttributeError:
    pass
else:
    ssl._create_default_https_context = _create_unverified_https_context

# ==========================================
# 2. æ ¸å¿ƒåŠŸèƒ½å‡½æ•¸
# ==========================================

def fetch_news():
    """æŠ“å– Google News RSS æ–°è"""
    news_items = []
    
    # é‡å°å°ç£ç†è²¡çš„é—œéµå­—æœå°‹ RSS
    urls = [
        ("ç¨…å‹™èˆ‡æ³•è¦", "https://news.google.com/rss/search?q=å°ç£+ç¨…å‹™+OR+æˆ¿åœ°åˆä¸€+OR+æ‰€å¾—ç¨…+when:1d&hl=zh-TW&gl=TW&ceid=TW:zh-TW"),
        ("é€€ä¼‘èˆ‡å¹´é‡‘", "https://news.google.com/rss/search?q=å°ç£+é€€ä¼‘é‡‘+OR+å‹ä¿+OR+å‹é€€+when:1d&hl=zh-TW&gl=TW&ceid=TW:zh-TW"),
        ("æŠ•è³‡èˆ‡ETF", "https://news.google.com/rss/search?q=å°ç£+ETF+é…æ¯+OR+é‡‘ç®¡æœƒ+when:1d&hl=zh-TW&gl=TW&ceid=TW:zh-TW"),
        ("æˆ¿ç”¢èˆ‡ä¿éšª", "https://news.google.com/rss/search?q=å°ç£+æˆ¿è²¸+OR+æ–°é’å®‰+OR+é•·ç…§ä¿éšª+when:1d&hl=zh-TW&gl=TW&ceid=TW:zh-TW")
    ]

    for category, url in urls:
        try:
            feed = feedparser.parse(url)
            # æ¯ä¸€é¡æŠ“å‰ 15 ç¯‡ï¼Œç¢ºä¿åŸæ–™å……è¶³
            for entry in feed.entries[:15]:
                news_items.append({
                    "category": category,
                    "title": entry.title,
                    "link": entry.link,
                    "source": entry.source.title if hasattr(entry, 'source') else "Google News",
                    "summary": entry.summary[:200] if hasattr(entry, 'summary') else ""
                })
        except Exception as e:
            print(f"Error fetching {category}: {e}")
            
    return news_items

def batch_generate_comments(selected_news):
    """æ‰¹æ¬¡ç”Ÿæˆè©•è«–"""
    
    # ã€é—œéµä¿®æ­£ã€‘å¼·åˆ¶æŒ‡å®šä½¿ç”¨ gemini-1.5-flash
    # é€™å€‹æ¨¡å‹æ¯å¤©æœ‰ 1,500 æ¬¡å…è²»é¡åº¦ï¼Œä¸”é€Ÿåº¦æœ€å¿«
    model_name = "gemini-1.5-flash"
    
    try:
        model = genai.GenerativeModel(model_name)
    except Exception:
        # å¦‚æœ flash çœŸçš„ä¹Ÿä¸èƒ½ç”¨ï¼Œé€€å›èˆŠç‰ˆ pro
        model = genai.GenerativeModel("gemini-pro")

    # æº–å‚™çµ¦ AI çš„è³‡æ–™åŒ…
    news_text_block = json.dumps([{
        "id": i, 
        "title": n['title'], 
        "summary": n['summary']
    } for i, n in enumerate(selected_news)], ensure_ascii=False)

    prompt = f"""
    ä½ æ˜¯å°ç£è³‡æ·±è²¡å‹™é¡§å•(IFA)ã€‚ä»¥ä¸‹æ˜¯ 6 å‰‡ç²¾é¸è²¡ç¶“æ–°èï¼š
    {news_text_block}

    è«‹é‡å°ã€Œæ¯ä¸€å‰‡ã€æ–°èï¼Œæ’°å¯«ç°¡çŸ­å°ˆæ¥­é»è©•ã€‚
    
    ã€æ ¼å¼è¦æ±‚ã€‘ï¼š
    è«‹å›å‚³ä¸€å€‹ç´” JSON Listï¼Œä¸è¦æœ‰ markdown æ¨™è¨˜ã€‚
    List ä¸­åŒ…å« 6 å€‹ç‰©ä»¶ï¼Œæ¯å€‹ç‰©ä»¶æ ¼å¼å¦‚ä¸‹ï¼š
    {{
        "id": (å°æ‡‰çš„æ–°èID),
        "advisor_view": "é¡§å•è§€é» (æ¢åˆ—å¼ï¼Œ2é»ï¼Œé—œæ³¨è³‡ç”¢å½±éŸ¿)",
        "action": "è¡Œå‹•å»ºè­° (1å¥)"
    }}
    """
    
    try:
        response = model.generate_content(prompt)
        # æ¸…ç†å›å‚³å­—ä¸²
        cleaned_text = response.text.replace("```json", "").replace("```", "").strip()
        comments_data = json.loads(cleaned_text)
        return comments_data
    except Exception as e:
        # å¦‚æœé‚„æ˜¯é‡åˆ° 429 éŒ¯èª¤ï¼Œåœ¨é€™è£¡æ””æˆªä¸¦é¡¯ç¤ºå‹å–„è¨Šæ¯
        if "429" in str(e):
            st.warning("âš ï¸ ç³»çµ±å¿™ç¢Œä¸­ (API é¡åº¦é™åˆ¶)ã€‚è«‹ç¨ç­‰ 1 åˆ†é˜å¾Œå†è©¦ã€‚")
        else:
            st.error(f"AI ç”Ÿæˆå¤±æ•—: {e}")
        return []

# ==========================================
# 3. æ•´åˆæµç¨‹ (åŠ ä¸Šå¿«å–æ©Ÿåˆ¶)
# ==========================================

@st.cache_data(ttl=3600, show_spinner=False)
def run_curation_pipeline(api_key):
    """
    1å°æ™‚å…§åªåŸ·è¡Œä¸€æ¬¡ï¼Œå¤§å¹…ç¯€çœé¡åº¦
    """
    genai.configure(api_key=api_key)
    
    # 1. æŠ“å–æ–°è
    raw_news = fetch_news()
    if not raw_news:
        return None, "ç„¡æ³•æŠ“å–æ–°è"

    # 2. å¤šæ¨£æ€§ç¯©é¸ (Python é‚è¼¯)
    selected_news = []
    seen_titles = set()
    categories = ["ç¨…å‹™èˆ‡æ³•è¦", "é€€ä¼‘èˆ‡å¹´é‡‘", "æŠ•è³‡èˆ‡ETF", "æˆ¿ç”¢èˆ‡ä¿éšª"]
    
    while len(selected_news) < 6 and raw_news:
        for cat in categories:
            candidates = [n for n in raw_news if n['category'] == cat and n['title'] not in seen_titles]
            if candidates:
                pick = candidates[0]
                selected_news.append(pick)
                seen_titles.add(pick['title'])
                if len(selected_news) >= 6: break
        
        if len(selected_news) < 6:
            remaining = [n for n in raw_news if n['title'] not in seen_titles]
            if not remaining: break
            pick = remaining[0]
            selected_news.append(pick)
            seen_titles.add(pick['title'])

    # 3. æ‰¹æ¬¡ç”Ÿæˆè©•è«–
    comments_data = batch_generate_comments(selected_news)
    
    # 4. çµ„åˆçµæœ
    final_results = []
    for news in selected_news:
        comment = next((c for c in comments_data if c.get('title') == news['title'] or c.get('id') == selected_news.index(news)), None)
        if not comment and len(comments_data) > selected_news.index(news):
            comment = comments_data[selected_news.index(news)]

        final_results.append({
            "news": news,
            "comment": comment
        })
        
    return final_results, None

# ==========================================
# 4. ä¸»ç¨‹å¼ä»‹é¢ (UI)
# ==========================================

def main():
    st.title("ğŸ¤– IFA æ™ºèƒ½æ–°èç­–å±•ç³»çµ±")
    st.caption("è‡ªå‹•å½™æ•´ç¨…å‹™ã€é€€ä¼‘ã€æŠ•è³‡èˆ‡æˆ¿ç”¢è³‡è¨Šï¼Œç”Ÿæˆé¡§å•è§€é»ã€‚")

    # è™•ç† API Key
    api_key = None
    if "GOOGLE_API_KEY" in st.secrets:
        api_key = st.secrets["GOOGLE_API_KEY"]
    else:
        api_key = st.sidebar.text_input("è«‹è¼¸å…¥ Google API Key", type="password")

    if not api_key:
        st.warning("è«‹å…ˆè¨­å®š API Key æ‰èƒ½é–‹å§‹é‹ä½œã€‚")
        return

    # æŒ‰éˆ•è§¸ç™¼
    if st.button("é–‹å§‹ç­–å±• (æ›´æ–°æ—¥å ±)"):
        with st.spinner("AI æ­£åœ¨é–±è®€ä¸¦æ•´ç†å…¨å°è²¡ç¶“æ–°è... (ç´„éœ€ 10-20 ç§’)"):
            results, error = run_curation_pipeline(api_key)
            
            if error:
                st.error(error)
            else:
                st.toast(f"è³‡æ–™ä¾†æºï¼šGoogle News | æ›´æ–°æ™‚é–“ï¼š{time.strftime('%H:%M')}")
                
                # é¡¯ç¤ºçµæœ (é›™æ¬„æ’ç‰ˆ)
                st.divider()
                cols = st.columns(2)
                
                for idx, item in enumerate(results):
                    news = item['news']
                    comment = item['comment']
                    
                    with cols[idx % 2]:
                        with st.container(border=True):
                            st.subheader(news['title'])
                            st.caption(f"ç”± {news['source']} ç™¼å¸ƒæ–¼ {news['category']}")
                            
                            advisor_view = "\n".join([f"- {p}" for p in comment.get('advisor_view', [])]) if comment else "AI ç”Ÿæˆä¸­æ–·"
                            action = comment.get('action', 'å»ºè­°è©³é–±åŸæ–‡') if comment else ""
                            
                            content = f"""
### ğŸ’¼ é¡§å•è§€é»
{advisor_view}

### ğŸš€ å»ºè­°è¡Œå‹•
{action}

[é–±è®€åŸæ–‡]({news['link']})
"""
                            st.markdown(content)
                            with st.expander("è¤‡è£½æ–‡æ¡ˆ"):
                                st.code(f"{news['title']}\n\n{content}", language="markdown")

if __name__ == "__main__":
    main()
