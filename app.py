import streamlit as st
import feedparser
import google.generativeai as genai
import json
import time
import ssl

# --- 0. Critical Fix: Global SSL Context Bypass ---
try:
    _create_unverified_https_context = ssl._create_unverified_context
except AttributeError:
    pass
else:
    ssl._create_default_https_context = _create_unverified_https_context

# --- Config & Layout ---
st.set_page_config(
    page_title="IFA è²¡ç¶“æ–°èè‡ªå‹•ç­–å±•ç³»çµ±",
    page_icon="ğŸ“°",
    layout="wide"
)

st.title("ğŸ“° IFA è²¡ç¶“æ–°èè‡ªå‹•ç­–å±•ç³»çµ±")
st.markdown("è‡ªå‹•æŠ“å–æ–°è RSS -> Gemini AI ç¯©é¸èˆ‡æ’°å¯« -> ç”¢å‡ºé¡§å•å¼æ‘˜è¦")

# --- 1. API Key Handling ---
def get_api_key():
    """
    Hybrid API Key Handling:
    1. Try loading from st.secrets
    2. Fallback to sidebar input
    3. Stop if no key
    """
    api_key = None
    
    # Attempt to load from secrets
    try:
        api_key = st.secrets["GOOGLE_API_KEY"]
    except Exception:
        pass
    
    # If not in secrets, ask in sidebar
    if not api_key:
        with st.sidebar:
            st.header("è¨­å®š")
            api_key = st.text_input("è«‹è¼¸å…¥ Google API Key", type="password")
            st.markdown("[å–å¾— Gemini API Key](https://aistudio.google.com/app/apikey)")
            
    if not api_key:
        st.warning("âš ï¸ è«‹æä¾› Google API Key ä»¥ç¹¼çºŒä½¿ç”¨ (å¯æ–¼ .streamlit/secrets.toml è¨­å®šæˆ–å·¦å´è¼¸å…¥)")
        st.stop()
        
    return api_key

# --- 2. Model Discovery ---
def get_active_model_name():
    """
    Dynamically find the best available model.
    Priority: "flash" > "pro" > "gemini-pro" (fallback)
    """
    try:
        models = list(genai.list_models())
        available_models = [m.name for m in models if 'generateContent' in m.supported_generation_methods]
        
        # Priority 1: Flash
        for m in available_models:
            if "flash" in m.lower():
                return m
        
        # Priority 2: Pro
        for m in available_models:
            if "pro" in m.lower():
                return m
                
        # Priority 3: First available
        if available_models:
            return available_models[0]
            
    except Exception as e:
        print(f"Model discovery error: {e}")
        
    return "models/gemini-pro"

# --- 3. RSS Data Source ---
def fetch_news():
    """Fetch latest articles from Google News RSS feeds with Mock Data fallback.
       Fetches up to 20 per feed to ensure enough candidates for AI selection.
    """
    # Google News RSS searches (reliable & usually no 403)
    rss_urls = [
        "https://news.google.com/rss/search?q=å°ç£+ä¿éšª+OR+é•·ç…§+OR+ç†è³ +OR+å¤±èƒ½+OR+å¥ä¿+when:1d&hl=zh-TW&gl=TW&ceid=TW:zh-TW",  # Risk & Insurance
        "https://news.google.com/rss/search?q=å°ç£+éºç”¢ç¨…+OR+è´ˆèˆ‡ç¨…+OR+ä¿¡è¨—+OR+éºå›‘+OR+ç¯€ç¨…+when:1d&hl=zh-TW&gl=TW&ceid=TW:zh-TW", # Estate & Tax
        "https://news.google.com/rss/search?q=å°ç£+ETF+OR+å°è‚¡+OR+é…æ¯+OR+è¯æº–æœƒ+é™æ¯+when:1d&hl=zh-TW&gl=TW&ceid=TW:zh-TW",      # Investment & Macro
        "https://news.google.com/rss/search?q=å°ç£+æˆ¿è²¸+OR+æˆ¿å¸‚+æ”¿ç­–+OR+æ–°é’å®‰+OR+è©é¨™+æ‰‹æ³•+when:1d&hl=zh-TW&gl=TW&ceid=TW:zh-TW"  # Living, Loans & Fraud
    ]
    
    articles = []
    seen_links = set()
    
    try:
        for url in rss_urls:
            # feedparser handles Google News RSS well without custom headers
            feed = feedparser.parse(url)
            
            # Check if feed is empty or faulty (some 403s result in empty feed without exception)
            if not feed.entries and feed.bozo:
                 # Just skip this feed if it fails cleanly, don't crash everything unless all fail
                 continue

            # Take top 20 from each feed
            for entry in feed.entries[:20]: 
                # Basic dedup
                if entry.link not in seen_links:
                    seen_links.add(entry.link)
                    
                    source = entry.get("source", {}).get("title", "Google News")
                    
                    articles.append({
                        "title": entry.title,
                        "link": entry.link,
                        "summary": entry.get("summary", ""),
                        "published": entry.get("published", ""),
                        "source": source
                    })
        
        if not articles:
            raise Exception("No articles fetched from any source.")
                    
    except Exception as e:
        st.error(f"Detailed Error: {e}")
        st.warning("âš ï¸ æª¢æ¸¬åˆ°ç¶²è·¯é€£ç·šç•°å¸¸ï¼Œç›®å‰é¡¯ç¤ºæ¸¬è©¦è³‡æ–™ (Mock Data) ä»¥ä¾›é è¦½ã€‚")
        
        # Mock Data Fallback
        mock_articles = [
            {
                "title": "è²¡æ”¿éƒ¨é å‘Šä¿®æ³• 2026å¹´èµ·åŠ å¯†è²¨å¹£ç²åˆ©é ˆç”³å ±æ‰€å¾—ç¨…",
                "source": "æ¸¬è©¦è³‡æ–™ä¾†æº",
                "link": "https://google.com",
                "summary": "è²¡æ”¿éƒ¨ä»Šæ—¥é å‘Šï¼Œå°‡é…åˆåœ‹éš›åé¿ç¨…è¶¨å‹¢ï¼Œç´å…¥å€‹äººåŠ å¯†è³‡ç”¢äº¤æ˜“æ‰€å¾—ï¼Œé è¨ˆ 2026 å¹´æ­£å¼ä¸Šè·¯ã€‚",
                "published": "2026-01-13"
            },
            {
                "title": "é€€ä¼‘é‡‘æº–å‚™ä¸è¶³ï¼Ÿä¸‰æ‹›æ•™ä½ è£œè¶³ç¼ºå£",
                "source": "æ¸¬è©¦è³‡æ–™ä¾†æº",
                "link": "https://google.com",
                "summary": "æ ¹æ“šæœ€æ–°èª¿æŸ¥ï¼Œåœ‹äººé€€ä¼‘é‡‘æº–å‚™æ™®éä¸è¶³ã€‚å°ˆå®¶å»ºè­°é€éå®šæœŸå®šé¡ã€é•·æœŸè¤‡åˆ©æ•ˆæœï¼Œææ—©è¦åŠƒé€€ä¼‘ç”Ÿæ´»ã€‚",
                "published": "2026-01-13"
            },
            {
                "title": "å…¨çƒç¶“æ¿Ÿæ”¾ç·© æŠ•è³‡äººæ‡‰é—œæ³¨é˜²ç¦¦å‹è³‡ç”¢",
                "source": "æ¸¬è©¦è³‡æ–™ä¾†æº",
                "link": "https://google.com",
                "summary": "IMF ä¸‹ä¿®å…¨çƒç¶“æ¿Ÿæˆé•·ç‡ï¼Œåˆ†æå¸«å»ºè­°æŠ•è³‡äººèª¿æ•´è³‡ç”¢é…ç½®ï¼Œå¢åŠ å‚µåˆ¸èˆ‡å…¬ç”¨äº‹æ¥­ç­‰é˜²ç¦¦å‹é¡è‚¡æ¯”é‡ã€‚",
                "published": "2026-01-13"
            },
            {
                "title": "æ–°é’å®‰æˆ¿è²¸æ”¿ç­–æˆæ•ˆèˆ‡é¢¨éšª",
                "source": "æ¸¬è©¦è³‡æ–™ä¾†æº",
                "link": "https://google.com",
                "summary": "æ”¿åºœæ¨å‡ºæ–°é’å®‰æˆ¿è²¸æ”¿ç­–ï¼Œå¸‚å ´åæ‡‰ç†±çƒˆï¼Œä½†å°ˆå®¶æé†’éœ€æ³¨æ„åˆ©ç‡è®Šå‹•é¢¨éšªèˆ‡è‡ªå‚™æ¬¾å£“åŠ›ã€‚",
                "published": "2026-01-13"
            },
            {
                "title": "ä¿éšªæ–°åˆ¶ä¸Šè·¯ï¼Œé•·ç…§éšªæ€éº¼è²·ï¼Ÿ",
                "source": "æ¸¬è©¦è³‡æ–™ä¾†æº",
                "link": "https://google.com",
                "summary": "é‡‘ç®¡æœƒé‡å°é•·ç…§éšªç™¼å¸ƒæ–°è¦å®šï¼Œå°ˆå®¶è§£ææ¢æ¬¾å·®ç•°ï¼Œå»ºè­°æ°‘çœ¾ä¾è‡ªèº«éœ€æ±‚ææ—©è¦åŠƒã€‚",
                "published": "2026-01-13"
            },
            {
                "title": "é«˜è‚¡æ¯ETFå¤¯ï¼Œæˆåˆ†è‚¡ç¯©é¸é‚è¼¯å¤§å…¬é–‹",
                "source": "æ¸¬è©¦è³‡æ–™ä¾†æº",
                "link": "https://google.com",
                "summary": "è¿‘æœŸé«˜è‚¡æ¯ETFå‚™å—æŠ•è³‡äººé’çï¼Œæœ¬æ–‡æ·±å…¥å‰–æå„å¤§ETFçš„é¸è‚¡é‚è¼¯èˆ‡ç¸¾æ•ˆè¡¨ç¾ã€‚",
                "published": "2026-01-13"
            }
        ]
        return mock_articles
        
    return articles

# --- 4. Gemini AI Logic ---
def filter_news_with_gemini(articles, model):
    """
    Step A: Batch Select.
    Send titles to Gemini, ask for top 6 indices relevant to Financial Planning.
    """
    titles = [f"{i}. {a['title']}" for i, a in enumerate(articles)]
    titles_text = "\n".join(titles)
    
    prompt = f"""
    You are an expert Financial Advisor editor.
    I have a list of new articles. Please identify the Top 6 articles for a "Full Spectrum Financial Plan".
    
    **Selection Criteria**:
    1. Quantity: **You MUST select EXACTLY 6 articles**. Do not return fewer than 6. Even if some articles are less important, pick the best available ones to fill the quota of 6.
    2. Diversity: MAXIMIZE TOPIC DIVERSITY. Try to pick from DIFFERENT categories (Tax, Insurance, Investment, Retirement, Estate, Loan).
       - Do NOT pick 6 articles about the same topic.
    
    Articles:
    {titles_text}
    
    Return a valid JSON list of integers representing the indices of the selected articles.
    Example output: [0, 4, 7, 12, 15, 18]
    """
    
    valid_indices = []
    try:
        response = model.generate_content(prompt, generation_config={"response_mime_type": "application/json"})
        indices = json.loads(response.text)
        # Ensure indices are integers and within range
        valid_indices = [i for i in indices if isinstance(i, int) and 0 <= i < len(articles)]
    except Exception as e:
        st.error(f"AI Filtering Error: {e}")
        valid_indices = []
        
    # --- Python Fallback Padding ---
    # Ensure we ALWAYS have 6 items. If AI returns < 6, fill with other articles.
    target_count = 6
    if len(valid_indices) < target_count:
        existing_ids = set(valid_indices)
        for i in range(len(articles)):
            if i not in existing_ids:
                valid_indices.append(i)
                existing_ids.add(i)
            
            if len(valid_indices) >= target_count:
                break
    
    return valid_indices[:target_count]

def batch_summarize_articles(articles, model):
    """
    Step B: Batch Rewrite.
    Generate summaries for ALL selected articles in ONE API call to avoid 429 Rate Limits.
    """
    # Construct a single prompt with all articles
    articles_text = ""
    for i, a in enumerate(articles):
        articles_text += f"""
        Article {i}:
        Title: {a['title']}
        Content: {a['summary']}
        ---
        """
        
    prompt = f"""
    You are an expert Independent Financial Advisor (IFA) in Taiwan.
    I have {len(articles)} news articles. Please generate a "Client-Ready Summary" for EACH one.
    
    Input Articles:
    {articles_text}
    
    Output Instructions:
    - Return a **pure JSON list** of objects.
    - Each object must correspond to an article in the input order.
    - Format for each object:
      {{
        "title": "News Title",
        "summary": "One concise sentence summarizing the core event (Traditional Chinese)",
        "advisor_view": ["Viewpoint 1", "Viewpoint 2"],
        "action": "One concrete actionable advice"
      }}
    """
    
    try:
        response = model.generate_content(prompt, generation_config={"response_mime_type": "application/json"})
        results = json.loads(response.text)
        
        # Validate list length
        if isinstance(results, list):
            return results
        else:
            st.error("AI returned invalid format (not a list).")
            return []
            
    except Exception as e:
        st.error(f"Batch Summarization Error: {e}")
        return []

# --- Main Execution Flow ---
def main():
    api_key = get_api_key()
    
    # Configure Gemini
    genai.configure(api_key=api_key)
    
    # Dynamic Model Discovery
    model_name = get_active_model_name()
    model = genai.GenerativeModel(model_name)
    st.toast(f"Using AI Model: {model_name}")

    if st.button("ğŸš€ é–‹å§‹ç­–å±• (Start Curation)", type="primary"):
        status_container = st.status("æ­£åœ¨è™•ç†ä¸­...", expanded=True)
        
        with status_container:
            # 1. Fetch
            st.write("ğŸ“¡ æ­£åœ¨æŠ“å– RSS æ–°èä¾†æº...")
            articles = fetch_news()
            
            # Debug: Check Raw Quantity
            st.write(f"ğŸ” Raw articles fetched: {len(articles)}")
            
            if not articles:
                st.error("æœªèƒ½æŠ“å–åˆ°ä»»ä½•æ–°è (No news fetched).")
                status_container.update(label="å¤±æ•—", state="error")
                return
            st.write(f"âœ… æŠ“å–å®Œæˆï¼Œå…± {len(articles)} ç¯‡æ–°èã€‚")
            
            # 2. Filter
            st.write("ğŸ§  AI æ­£åœ¨ç¯©é¸æœ€æ”¸é—œ (Full Spectrum Financial Planning) çš„ 6 ç¯‡æ–‡ç« ...")
            selected_indices = filter_news_with_gemini(articles, model)
            
            if not selected_indices:
                st.warning("AI æœªèƒ½é¸å‡ºé©åˆçš„æ–‡ç« ï¼Œæˆ–å›æ‡‰æ ¼å¼éŒ¯èª¤ã€‚")
                status_container.update(label="å®Œæˆ (ç„¡é¸éŒ„)", state="complete")
                return
                
            selected_articles = [articles[i] for i in selected_indices]
            st.write(f"âœ… ç¯©é¸å®Œæˆï¼Œé¸å‡ºç´¢å¼•: {selected_indices}")
            
            # 3. Batch Summarize
            st.write(f"âœï¸ AI æ­£åœ¨æ’°å¯« {len(selected_articles)} ç¯‡æ‘˜è¦ (Batch Process)...")
            summaries_data = batch_summarize_articles(selected_articles, model)
            
            if not summaries_data:
                st.warning("AI æš«æ™‚ç„¡æ³•é€£ç·š (ç”Ÿæˆå¤±æ•—)ï¼Œè«‹ç›´æ¥åƒè€ƒåŸæ–‡é€£çµã€‚")
                summaries_data = [{"title": a["title"], "summary": "AI ç”Ÿæˆå¤±æ•—", "advisor_view": [], "action": "è«‹é–±è®€åŸæ–‡"} for a in selected_articles]

            status_container.update(label="ğŸ‰ ç­–å±•å®Œæˆ!", state="complete", expanded=False)

        # 4. Display (Grid Layout)
        st.divider()
        st.subheader(f"ğŸ“‹ ç­–å±•çµæœ ({len(summaries_data)} ç¯‡)")
        
        cols = st.columns(2) # Create 2 columns
        
        # Iterate and display in grid
        for index, item in enumerate(summaries_data):
            # Fallback for missing keys
            title = item.get('title', 'Unknown Title')
            summary = item.get('summary', 'No summary.')
            views = item.get('advisor_view', [])
            action = item.get('action', 'No advice.')
            
            # Get original link
            # Safety check: if summaries count mismatches selected count, prevent index error
            if index < len(selected_articles):
                original_link = selected_articles[index]['link']
                original_source = selected_articles[index].get('source', 'News')
            else:
                original_link = "#"
                original_source = "News"
            
            # Construct Display Text
            view_bullets = "\n".join([f"- {v}" for v in views]) if views else ""
            display_text = f"### ğŸ“° {title}\n**æ‘˜è¦**ï¼š{summary}\n\n"
            if view_bullets:
                display_text += f"**é¡§å•è§€é»**ï¼š\n{view_bullets}\n\n"
            if action:
                display_text += f"**è¡Œå‹•å»ºè­°**ï¼š{action}"
            
            with cols[index % 2]: # Alternate columns
                with st.container(border=True):
                    # Render Content
                    st.markdown(display_text)
                    
                    # Source Link
                    st.caption(f"ä¾†æº: {original_source} | [é–±è®€åŸæ–‡]({original_link})")
                    
                    # Copy Block
                    st.code(display_text, language="markdown")
                    
if __name__ == "__main__":
    main()
