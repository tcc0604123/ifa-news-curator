import streamlit as st
import feedparser
import google.generativeai as genai
import json
import time
import ssl

# --- 0. Critical Fix: Global SSL Context Bypass ---
try:
    _create_unverified_https_context = ssl._create_unverified_context
except AttributeError:
    pass
else:
    ssl._create_default_https_context = _create_unverified_https_context

# --- Config & Layout ---
st.set_page_config(
    page_title="IFA è²¡ç¶“æ–°èè‡ªå‹•ç­–å±•ç³»çµ±",
    page_icon="ğŸ“°",
    layout="wide"
)

st.title("ğŸ“° IFA è²¡ç¶“æ–°èè‡ªå‹•ç­–å±•ç³»çµ±")
st.markdown("è‡ªå‹•æŠ“å–æ–°è RSS -> Gemini AI ç¯©é¸èˆ‡æ’°å¯« -> ç”¢å‡ºé¡§å•å¼æ‘˜è¦")

# --- 1. API Key Handling ---
def get_api_key():
    """
    Hybrid API Key Handling:
    1. Try loading from st.secrets
    2. Fallback to sidebar input
    3. Stop if no key
    """
    api_key = None
    
    # Attempt to load from secrets
    try:
        api_key = st.secrets["GOOGLE_API_KEY"]
    except Exception:
        pass
    
    # If not in secrets, ask in sidebar
    if not api_key:
        with st.sidebar:
            st.header("è¨­å®š")
            api_key = st.text_input("è«‹è¼¸å…¥ Google API Key", type="password")
            st.markdown("[å–å¾— Gemini API Key](https://aistudio.google.com/app/apikey)")
            
    if not api_key:
        st.warning("âš ï¸ è«‹æä¾› Google API Key ä»¥ç¹¼çºŒä½¿ç”¨ (å¯æ–¼ .streamlit/secrets.toml è¨­å®šæˆ–å·¦å´è¼¸å…¥)")
        st.stop()
        
    return api_key

# --- 2. Model Discovery ---
def get_active_model_name():
    """
    Dynamically find the best available model.
    Priority: "1.5-flash" > "flash" > "pro" > "gemini-pro" (fallback)
    """
    try:
        models = list(genai.list_models())
        available_models = [m.name for m in models if 'generateContent' in m.supported_generation_methods]
        
        # Priority 0: Explicit 1.5 Flash (Most Stable Quota)
        for m in available_models:
            if "1.5-flash" in m.lower() and "exp" not in m.lower(): # Avoid excessive experimental versions if possible
                return m

        # Priority 1: Any Flash
        for m in available_models:
            if "flash" in m.lower():
                return m
        
        # Priority 2: Pro
        for m in available_models:
            if "pro" in m.lower():
                return m
                
        # Priority 3: First available
        if available_models:
            return available_models[0]
            
    except Exception as e:
        print(f"Model discovery error: {e}")
        
    return "models/gemini-pro"

# ... (fetch_news, filter_news_with_gemini, batch_summarize_articles remain same logic, just indentation check) ...

# --- 5. Caching Pipeline ---
@st.cache_data(ttl=3600, show_spinner="æ­£åœ¨åŸ·è¡Œ AI ç­–å±•æµç¨‹ (æ¯å°æ™‚æ›´æ–°)...")
def run_curation_pipeline(api_key):
    """
    Executes the full curation flow: Fetch -> Filter -> Summarize.
    Cached for 1 hour to prevent API quota waste.
    """
    # Configure GenAI
    genai.configure(api_key=api_key)
    model_name = get_active_model_name()
    model = genai.GenerativeModel(model_name)
    
    # 1. Fetch
    articles = fetch_news()
    if not articles:
        return {"error": "No news fetched."}
        
    # 2. Filter
    selected_indices = filter_news_with_gemini(articles, model)
    if not selected_indices:
        return {"error": "AI filtering failed."}
        
    selected_articles = [articles[i] for i in selected_indices]
    
    # 3. Batch Summarize
    summaries_data = batch_summarize_articles(selected_articles, model)
    
    return {
        "status": "success",
        "model_used": model_name,
        "data": summaries_data,
        "selected_articles": selected_articles # Keep original for links
    }

# --- Main Execution Flow ---
def main():
    api_key = get_api_key()

    if st.button("ğŸš€ é–‹å§‹ç­–å±• (Start Curation)", type="primary"):
        # Run the cached pipeline
        # Note: We pass api_key so cache invalidates if key changes, 
        # but mostly it's for the function to usage it without global scope issues.
        
        result = run_curation_pipeline(api_key)
        
        if result.get("error"):
            st.error(result["error"])
            return

        summaries_data = result.get("data", [])
        selected_articles = result.get("selected_articles", [])
        model_used = result.get("model_used", "Unknown")
        
        st.toast(f"Using AI Model: {model_used} (Cached)")
        st.success(f"ğŸ‰ ç­–å±•å®Œæˆ! (ä¾†æº: {len(summaries_data)} ç¯‡)")

        # 4. Display (Grid Layout)
        st.divider()
        st.subheader(f"ğŸ“‹ ç­–å±•çµæœ")
        
        cols = st.columns(2) # Create 2 columns
        
        # Iterate and display in grid
        for index, item in enumerate(summaries_data):
            # Fallback for missing keys
            title = item.get('title', 'Unknown Title')
            summary = item.get('summary', 'No summary.')
            views = item.get('advisor_view', [])
            action = item.get('action', 'No advice.')
            
            # Get original link
            if index < len(selected_articles):
                original_link = selected_articles[index]['link']
                original_source = selected_articles[index].get('source', 'News')
            else:
                original_link = "#"
                original_source = "News"
            
            # Construct Display Text
            view_bullets = "\n".join([f"- {v}" for v in views]) if views else ""
            display_text = f"### ğŸ“° {title}\n**æ‘˜è¦**ï¼š{summary}\n\n"
            if view_bullets:
                display_text += f"**é¡§å•è§€é»**ï¼š\n{view_bullets}\n\n"
            if action:
                display_text += f"**è¡Œå‹•å»ºè­°**ï¼š{action}"
            
            with cols[index % 2]: # Alternate columns
                with st.container(border=True):
                    # Render Content
                    st.markdown(display_text)
                    
                    # Source Link
                    st.caption(f"ä¾†æº: {original_source} | [é–±è®€åŸæ–‡]({original_link})")
                    
                    # Copy Block
                    st.code(display_text, language="markdown")
                    
if __name__ == "__main__":
    main()
